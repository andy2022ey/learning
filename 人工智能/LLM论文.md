# ChatGLM
[General Language Model Pretraining with Autoregressive Blank Infilling](https://aclanthology.org/2022.acl-long.26.pdf)

# GPT-Q
[ACCURATE POST-TRAINING QUANTIZATION FOR GENERATIVE PRE-TRAINED TRANSFORMERS](https://arxiv.org/pdf/2210.17323.pdf)
